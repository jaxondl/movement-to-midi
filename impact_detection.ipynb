{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06c995c8",
   "metadata": {},
   "source": [
    "# Impact Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07cfc4ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T21:27:29.200079Z",
     "start_time": "2022-11-30T21:27:27.328460Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2764e28",
   "metadata": {},
   "source": [
    "## Load Pose Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2aa306c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T22:58:04.062127Z",
     "start_time": "2022-11-30T22:58:04.043474Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to interpolate missing pose estimates\n",
    "# https://stackoverflow.com/questions/6518811/interpolate-nan-values-in-a-numpy-array\n",
    "def interpolate_pose_estimates(a):\n",
    "    found = a != 0\n",
    "    not_found = a == 0\n",
    "    xp = found.nonzero()[0]\n",
    "    fp = a[found]\n",
    "    x  = not_found.nonzero()[0]\n",
    "\n",
    "    a[not_found] = np.interp(x, xp, fp)\n",
    "    return a\n",
    "\n",
    "# function to load pose estimates\n",
    "def load_pose_estimates(load_dir, vid_name, fps):\n",
    "    json_files = sorted(os.listdir(os.path.join(load_dir, vid_name)))\n",
    "    json_paths = [(int(json_file.split('_')[1]), os.path.join(load_dir, vid_name, json_file)) for json_file in json_files if '.json' in json_file]\n",
    "    n_frames = len(json_paths)\n",
    "    \n",
    "    pose_x = np.empty((n_frames, 18))\n",
    "    pose_y = np.empty((n_frames, 18))\n",
    "    pose_c = np.empty((n_frames, 18))\n",
    "    time_stamps = np.empty((n_frames))\n",
    "    for frm, json_path in json_paths: \n",
    "        with open(json_path, 'r') as f:\n",
    "            json_dict = json.load(f)\n",
    "        x = json_dict['people'][0]['pose_keypoints_2d'][0::3]\n",
    "        y = json_dict['people'][0]['pose_keypoints_2d'][1::3]\n",
    "        c = json_dict['people'][0]['pose_keypoints_2d'][2::3]\n",
    "        pose_x[frm] = x\n",
    "        pose_y[frm] = y\n",
    "        pose_c[frm] = c\n",
    "        time_stamps[frm] = frm/fps\n",
    "        \n",
    "    # interpolate missing pose estimates\n",
    "    for limb in range(18):\n",
    "        pose_x[:,limb] = interpolate_pose_estimates(pose_x[:,limb])\n",
    "        pose_y[:,limb] = interpolate_pose_estimates(pose_y[:,limb])\n",
    "        \n",
    "    print(f'Interpolation correct?: {(pose_x != 0).all() and (pose_y != 0).all()}')\n",
    "        \n",
    "    return pose_x, pose_y, pose_c, time_stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1289a060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T22:58:06.707424Z",
     "start_time": "2022-11-30T22:58:06.304280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation correct?: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((4606, 18), (4606, 18), (4606, 18), (4606,))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pose estimates for j1\n",
    "load_dir = os.path.join('data', 'output_jsons')\n",
    "vid_name = 'j1'\n",
    "fps = 30\n",
    "\n",
    "pose_x, pose_y, pose_c, time_stamps = load_pose_estimates(load_dir, vid_name, fps)\n",
    "pose_x.shape, pose_y.shape, pose_c.shape, time_stamps.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcae34f",
   "metadata": {},
   "source": [
    "## Detect Impact Points\n",
    "\n",
    "https://cmu-perceptual-computing-lab.github.io/openpose/web/html/doc/md_doc_02_output.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf934de3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-30T22:58:47.607352Z",
     "start_time": "2022-11-30T22:58:47.590220Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4606, 4), (4606,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to detect impact points\n",
    "def detect_impact_points(pose_x, pose_y, pose_c, time_stamps, limb_indices):\n",
    "    assert len(pose_x) == len(pose_y) and len(pose_x) == len(pose_c) and len(pose_x) == len(time_stamps)\n",
    "    \n",
    "    # detect impact points for each limb\n",
    "    n_frames = len(time_stamps)\n",
    "    n_limbs = len(limb_indices)\n",
    "    impact_points = np.zeros((n_frames, n_limbs), dtype=bool)\n",
    "    for i, limb in enumerate(limb_indices):\n",
    "        x = pose_x[:,limb]\n",
    "        y = pose_y[:,limb]\n",
    "        c = pose_c[:,limb] # just a confidence value, probably not necessary\n",
    "        limb_impacts = np.zeros((n_frames), dtype=bool)\n",
    "        \n",
    "        # to do: detect impact points here\n",
    "\n",
    "        impact_points[:,i] = limb_impacts\n",
    "    \n",
    "    assert len(impact_points) == len(time_stamps)\n",
    "    return impact_points, time_stamps\n",
    "\n",
    "# testing\n",
    "limb_indices = [4, 7, 10, 13] # hands and feet indices in COCO format\n",
    "impact_points, time_stamps = detect_impact_points(pose_x, pose_y, pose_c, time_stamps, limb_indices)\n",
    "impact_points.shape, time_stamps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0196834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T20:51:21.627457Z",
     "start_time": "2022-11-16T20:51:21.623590Z"
    }
   },
   "outputs": [],
   "source": [
    "# save results to file\n",
    "save_dir = os.path.join('data', 'impact_points')\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "np.save(os.path.join(save_dir, f'{vid_name}_impact_points.npy'), impact_points)\n",
    "np.save(os.path.join(save_dir, f'{vid_name}_time_stamps.npy'), time_stamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe3cac3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Run on All Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e579c684",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T20:51:24.957205Z",
     "start_time": "2022-11-16T20:51:21.628768Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "a1\n",
      "----------\n",
      "a2\n",
      "----------\n",
      "e1\n",
      "----------\n",
      "e2\n",
      "----------\n",
      "e3\n",
      "----------\n",
      "j1\n",
      "----------\n",
      "j2\n",
      "----------\n",
      "u1\n",
      "----------\n",
      "u2\n"
     ]
    }
   ],
   "source": [
    "# run impact detection for all videos\n",
    "load_dir = os.path.join('data', 'output_jsons')\n",
    "vid_info_df = pd.read_csv(os.path.join('video', 'video_info.csv'), index_col='vid_name')\n",
    "limb_indices = [4, 7, 10, 13] # hands and feet indices in COCO format\n",
    "\n",
    "save_dir = os.path.join('data', 'impact_points')\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# iterate over all videos\n",
    "for vid_name in vid_info_df.index:\n",
    "    if vid_name != 'group':\n",
    "        print(10 * '-')\n",
    "        print(vid_name)\n",
    "        \n",
    "        # load pose estimates\n",
    "        fps = vid_info_df.loc[vid_name]['fps']\n",
    "        pose_x, pose_y, pose_c, time_stamps = load_pose_estimates(load_dir, vid_name, fps)\n",
    "        \n",
    "        # detect and save impact points and timestamps\n",
    "        impact_points, time_stamps = detect_impact_points(pose_x, pose_y, pose_c, time_stamps, limb_indices)\n",
    "        np.save(os.path.join(save_dir, f'{vid_name}_impact_points.npy'), impact_points)\n",
    "        np.save(os.path.join(save_dir, f'{vid_name}_time_stamps.npy'), time_stamps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:video]",
   "language": "python",
   "name": "conda-env-video-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
